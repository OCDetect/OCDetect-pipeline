Index: main.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import os\nimport gc\n\nimport sklearn.model_selection\nimport yaml\nimport sys\nimport socket\nfrom data_preparation.prepare import prepare_data, get_data_path_variables, load_data_preparation_settings\nfrom misc.csv_loader import load_subject\nfrom data_cleansing.helpers.definitions import Sensor\nfrom data_cleansing.modules.filter import run_data_cleansing\nfrom misc import logger\nfrom misc.export import export_data\nfrom data_cleansing.modules import relabel\nimport pandas as pd\nimport getpass\nfrom machine_learning.ml_main import ml_pipeline\nfrom copy import deepcopy\nimport threading\nimport concurrent.futures\nfrom multiprocessing import Manager, Lock\n\n\ndef main(config: dict, settings: dict) -> int:\n    #so\n    data_cleansing = settings[\"data_cleansing\"]\n    data_preparation = settings[\"data_preparation\"]\n    machine_learning = settings[\"machine_learning\"]\n\n    set_test_settings(settings) if settings[\"testing\"] else None # set subjects and window_size to test settings if testing: True\n\n    \"\"\"\n    Function to run the entire preprocessing pipeline, from data loading to cleaning to relabeling etc.\n    AND/OR run the data cleansing and machine learning pipeline, respectively.\n    :param settings: dict containing study wide settings\n    :param config: dict containing configuration information, e.g. folders, filenames or other settings\n    :return: int: Exit code\n    \"\"\"\n    threads = []\n    futures = []\n    try:\n        already_done = pd.read_csv(config[\"output_folder\"] + \"prep_params.csv\", index_col=False)\n    except FileNotFoundError:\n        already_done = []  # TODO to be tested for data_cleansing = True\n    if data_cleansing:\n        with Manager() as manager:\n            #subj_loaded = manager.dict()\n            with concurrent.futures.ThreadPoolExecutor(max_workers=32) as TPE:\n                for subject in settings[\"all_subjects\"]:\n                    if settings[\"test_filters\"]:\n                        grid_definition = {\n                            \"short_succession_time\": settings[\"short_succession_time\"],\n                            \"magnitude_window_size\": settings[\"magnitude_window_size\"],\n                            \"magnitude_threshold\": settings[\"magnitude_threshold\"],\n                            \"magnitude_overlap\": settings[\"magnitude_overlap\"],\n                            \"min_time_in_s_before_label\": settings[\"min_time_in_s_before_label\"]\n                        }\n                        grid = sklearn.model_selection.ParameterGrid(grid_definition)\n                        for i, settings_values in enumerate(grid):\n                            cur_settings = deepcopy(settings)\n                            already_done_candidates = already_done[already_done.subject==subject].copy()\n                            for key, val in settings_values.items():\n                                cur_settings[key] = val\n                                already_done_candidates = already_done_candidates[already_done_candidates[key]==val]\n                            if len(already_done_candidates) != 0:\n                                continue\n                            cur_settings[\"repetition\"] = i\n                            t = TPE.submit(data_cleansing_worker, *(subject, config, cur_settings))#, subj_loaded))\n                            futures.append(t)\n\n                    else:  # TODO: repair filters with lists to single value\n                        t = threading.Thread(target=data_cleansing_worker, args=(subject, config, settings))\n                        threads.append(t)\n                        t.start()\n                for index, thread in enumerate(threads):\n                    gc.collect()\n                    thread.join()\n                for future in futures:\n                    future.result()\n\n        logger.info(\"Finished running prepocessing\")\n    if data_preparation:\n        labels, features, users, feature_names = prepare_data(settings, config, raw=settings.get(\"raw_features\", True))\n    if machine_learning:\n        if not data_preparation:\n            # load prepared data\n            logger.info(\"Read in prepared data\")\n\n            use_filter, use_scaling, resample, use_undersampling, use_oversampling = load_data_preparation_settings(\n                settings)\n            if resample and not (use_undersampling or use_oversampling):\n                logger.debug(f\"You need to set your resampling methode in: {settings}\")\n\n            window_size, subjects, subjects_folder_name, sub_folder_path, export_path, scaling, filtering, raw_str = get_data_path_variables(\n                use_scaling, use_filter, config, settings)\n\n            logger.info(f\"Using path: {export_path}{sub_folder_path}\")\n            logger.info(f\"Scaled data: {scaling}; Filtered data: {filtering}\")\n\n            features = pd.read_csv(f\"{export_path}{sub_folder_path}/features_{filtering}_{scaling}{raw_str}.csv\")\n            labels = pd.read_csv(f\"{export_path}{sub_folder_path}/labels_{filtering}_{scaling}{raw_str}.csv\")\n            users = pd.read_csv(f\"{export_path}{sub_folder_path}/users_{filtering}_{scaling}{raw_str}.csv\")\n            feature_names = pd.read_csv(f\"{export_path}{sub_folder_path}/feature_names_{filtering}_{scaling}{raw_str}.csv\").iloc[:, 0].tolist()\n        seed = settings.get(\"seed\")\n        ml_pipeline(features, users, labels, feature_names, seed, settings, config)\n\n    return 0\n\n\ncopy_lock = threading.Lock()\n\n\ndef set_test_settings(settings: dict):\n    settings[\"all_subjects\"] = settings[\"test_subjects\"]\n    settings[\"ocd_diagnosed_subjects\"] = settings[\"test_subjects\"]\n    settings[\"window_size\"] = settings[\"test_window_size\"]\n\n\ndef data_cleansing_worker(subject: str, config: dict, settings: dict): # , subjects_loaded: dict):\n    subject = str(subject)\n    if len(subject) == 1:\n        subject = \"0\" + subject\n    export_subfolder = config.get(\"export_subfolder\")\n    if not (os.path.isdir(export_subfolder)):\n        os.mkdir(export_subfolder)\n    if os.path.isfile(export_subfolder + \"exported.txt\"):\n        with open(export_subfolder + \"exported.txt\", \"r\") as f:\n            out = False\n            for line in f:\n                if line.strip() == subject:\n                    out = True\n        if out:\n            return\n    else:\n        with open(export_subfolder + \"exported.txt\", \"w\") as f:\n            pass\n    logger.info(f\"########## Starting to run on subject {subject} ##########\")\n    logger.info(f\"##### Loading subject {subject} #####\")\n\n    with copy_lock:\n        recordings_list = deepcopy(load_subject(subject, config, settings))\n\n    logger.info(f\"##### Cleaning subject {subject}:{settings.get('repetition')} #####\")\n    cleaned_data = run_data_cleansing(recordings_list, subject, config, Sensor.ACCELEROMETER, settings)\n    for item in cleaned_data:\n        item.clear()\n        del item\n    del cleaned_data\n    gc.collect()\n    return\n    if not settings[\"run_export\"]:\n        for item in recordings_list:\n            item.clear()\n\n        for item in cleaned_data:\n            item.clear()\n        del recordings_list, cleaned_data\n        gc.collect()\n        return\n    labeled_data = relabel(cleaned_data, config, settings, subject)\n    logger.info(f\"##### Exporting subject {subject} #####\")\n    export_data(labeled_data, config, settings, subject)\n    logger.info(f\"########## Finished running on subject {subject} ##########\")\n    for item in recordings_list:\n        item.clear()\n    for item in cleaned_data:\n        item.clear()\n    for item in labeled_data:\n        item.clear()\n    del recordings_list, cleaned_data, labeled_data  # hopefully fix memory-caused sigkill...\n    gc.collect()\n\n\nif __name__ == \"__main__\":\n    if len(sys.argv) > 1:\n        config_file_name = sys.argv[1]\n        logger.debug(f\"Running with config file: '{config_file_name}'\")\n    else:\n        config_file_name = \"misc/config/config.yaml\"\n        logger.debug(f\"No config passed via parameters, running with default: '{config_file_name}'\")\n    username = getpass.getuser()\n    try:\n        with open(config_file_name, \"r\") as config_stream:\n            configs = yaml.safe_load(config_stream)\n            possible_configs = [list(entry.values())[0] for entry in configs if\n                             list(entry.values())[0].get(\"hostname\", \"\") == socket.gethostname() or\n                                socket.gethostname() in list(entry.values())[0].get(\"hostname\", \"\")]\n            active_config = [x for x in possible_configs if x.get(\"username\",0) == username][0] if len(possible_configs) > 1 else possible_configs[0]\n        with open(\"misc/config/settings.yaml\", \"r\") as settings_stream:\n            # settings = list(yaml.load_all(settings_stream, Loader=yaml.SafeLoader))\n            settings = yaml.safe_load(settings_stream)\n    except FileNotFoundError:\n        logger.error(f\"Could not load config file {config_file_name}, exiting...\")\n        sys.exit(1)\n    except IndexError:\n        logger.error(f\"Hostname {socket.gethostname()} not contained in config file '{config_file_name}', exiting...\")\n        sys.exit(1)\n    main(config=active_config, settings=settings)\n    sys.exit(0)\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/main.py b/main.py
--- a/main.py	
+++ b/main.py	
@@ -22,7 +22,7 @@
 
 
 def main(config: dict, settings: dict) -> int:
-    #so
+my suggestion
     data_cleansing = settings["data_cleansing"]
     data_preparation = settings["data_preparation"]
     machine_learning = settings["machine_learning"]
